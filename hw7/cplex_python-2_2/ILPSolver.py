
import pdb
import sys
import os
import re
import operator

binary_variables=[]
timing_variables=[]

max_latency = 30
num_processors = 4
num_cycles = 4
ASAP=False
ALAP=False

def exactILPScheduling(dataFlowGraph=None,costtable=None,ASAP=False,ALAP=False):
	ASAP=ASAP
	ALAP=ALAP
	solverInput="./results/"+dataFlowGraph.name+"_CPLEX"+".lp"  #Name of ILP formulation file will be sm_CPLEX.lp 
	solverOutput="./results/"+dataFlowGraph.name+"_CPLEX"+".results" #Results generated by CPLEX will be written to sm_CPLEX.results
	generateILPModel(dataFlowGraph,costtable,filename=solverInput) #Generates the ILP formulation and writes them to sm_CPLEX.lp
	comm="python2 ./qcpex.py {f} o > {f2}".format(f=solverInput,f2=solverOutput)
	os.system(comm) #CPLEX call to solve the ILP formulation

	# Following lines interpret results written by CPLEX. Start time, resource type and latency for each node are determined and schedule is printed 
	result_hash = interpretCPLEX(filename=solverOutput) 
	scheduling_results = {}
	for i in range(max_latency):
		scheduling_results[i]=[]
	for node in dataFlowGraph.nodes:
		for i in range(node.asap, node.alap):
			for cycle in range(num_cycles):
				name=generateNodeControlStep(node,i,cycle)
				if result_hash[name]==1:
					print name
					namesplit = name.split("_")
					scheduling_results[int(namesplit[1])] += [namesplit[0]+"_" + namesplit[2]]
					break
	#	for resource in costtable.nodeRes_table[node]:
	#		name=mappingName(node,resource)
	#		if result_hash[name]==1:
	#			node.assigned_resource=resource
	#			break
	#	for l in range(node.assigned_resource.latency):
	#		scheduling_results[node.start_time+l].append((node.name, node.assigned_resource.name))
	for i in range(1, max_latency):
		print i , scheduling_results[i]

#Interprets results written to sm_CPLEX.results
def interpretCPLEX(filename):
	solver_hash = {}
	start_record = False
	f = open(filename,'r')
	for line in f.readlines():
		if not re.search("\w+",line):
			continue

		if re.search("Maximum bound violation",line):
			start_record = False

		if start_record:
			binding_line = re.split(':',line)
			for item in re.split(" *",binding_line[0]):	## cutting out spaces at both ends
				if re.search("\w",item):
					variable = item
			value = re.split('=', binding_line[1])[-1]
			value = re.split(" *",value)[1]
			value = re.split("\n",value)[0]
			if not variable in solver_hash.keys():
				solver_hash[variable]=float(value)

		if re.search("Objective value",line) != None:
			value = re.split(' *= *',line)[1]
			value = re.split("\n",value)[0]
			solver_hash['Objective value']=float(value)
			start_record = True

	if solver_hash == {}:
		pdb.set_trace()
		print("no solution for rule {rid} during bottom-up scheduling".format(rid = self.associated_rule.id))
		pdb.set_trace()

	f.close()

	return solver_hash

#Creates set of equations/ inequalities for ILP using the dependency graph and cost table
def generateILPModel(dfg,cost_table,filename=''):
	
	global binary_variables, timing_variables
	# ilpstr is the string that will be written to sm_CPLEX.lp
	# Data written to sm_CPLEX.lp includes:
	ilpstr=''
	# (1) Objective function, i.e., what needs to be minimized?
	ilpstr=ilpstr+generateObjectives(dfg,cost_table)
	# (2) Node Constraints (control step, dependency and mapping constraints) 
	ilpstr=ilpstr+generateNodeConstraints(dfg,cost_table)
	# (3) Resource Concurrency Constraints
	if not (ASAP or ALAP):
		ilpstr=ilpstr+generateResourceConcurrencyConstraints(dfg,cost_table)
	ilpstr = ilpstr + generateProcessorConstraints(dfg, cost_table)
	# binary_variables can be equal to either 0 or 1,
	#timing variables (store node start times and latencies) are positive integers
	binary_variables=list(set(binary_variables))
	timing_variables=list(set(timing_variables))
	# (4) Bounds on variable values
	ilpstr=ilpstr+generateVarBounds()
	# (5) List of binary variables
	ilpstr=ilpstr+generateVarTypes()
	ilpstr=ilpstr+"End\n"

	f=None
	if filename=='':
		f=sys.stdout
	else:
		f=open(filename,'w')
	f.write(ilpstr)
	if filename!='':
		f.close()

# Generates objective function (minimizing latency for this example)
def generateObjectives(dfg,cost_table):
	bstr='\nMinimize\n'
	bstr=bstr+"\t obj : latency\n"
	bstr=bstr+"\nSubject To\n"
	nodenames = []
	for sink in dfg.sinks:
		bstr=bstr+"latency - "
		for cycle in range(num_cycles):
			nodenames.append(generateNodeStartTime(sink,cycle))
		bstr += " - ".join(nodenames)
		bstr += " = 0\n"
	for i in range(len(nodenames)-1):
		bstr = bstr + nodenames[i] + " - " + nodenames[i+1] + " <= 0 \n"
			
	return bstr

# Sorts nodes topologically from source to sink and generates the 3 types of node constraints 
def generateNodeConstraints(dfg,cost_table):
	bstr = ""
	topological_sort = dfg.topologicalSort(source2sink=True)
	sorted_levels = sortDictByKeys(topological_sort)
	bstr = bstr  + generateNodeControlStepConstraints(sorted_levels)
	bstr = bstr + generateNodeDependencyConstraints(sorted_levels)
	bstr = bstr + generateNodeMappingConstraints(sorted_levels,cost_table)
	return bstr

# Generates constraints for unique start time for each node, based on the ASAP, ALAP schedules
def generateNodeControlStepConstraints(sorted_levels):
	bstr="\n\\ Node Control Step Constraints\n"
	for cycle in range(num_cycles):
		for (level, nodes) in sorted_levels:
			for node in nodes:
				bstr = bstr + node.name + "_START_" + str(cycle)
				for i in range(node.asap, node.alap):
					bstr = bstr + " - {i} ".format(i=i) + generateNodeControlStep(node,i,cycle)
				bstr = bstr + " = 0\n" 
				stepnames=[]
				for i in range(node.asap,node.alap):
					stepnames.append(generateNodeControlStep(node,i,cycle))
				#stepnames = [s + "_{num}".format(num = str(cycle)) for s in stepnames]
				if cycle == num_cycles-1:
					bstr=bstr + " + ".join(stepnames) + ' = 1\n'
				else:
					bstr=bstr + " + ".join(stepnames) + ' = 1\n'
		bstr += "\n"
	return bstr

# Generates node dependency constraints
def generateNodeDependencyConstraints(sorted_levels):
	bstr="\n\\ Dependency Constraints\n"
	for cycle in range(num_cycles):
		for (level, nodes) in sorted_levels:
			for node in nodes:
				for edge in node.going_out_edges:
					bstr = bstr + generateNodeStartTime(node,cycle) + " - " + generateNodeStartTime(edge.tail,cycle) + " <= -1\n" 
	return bstr

# Generates constraints on mapping of resources to nodes and latency for each resource
def generateNodeMappingConstraints(sorted_levels,cost_table):
	bstr = "\n\\ Mapping Constraints\n"
	for (level,nodes) in sorted_levels:
		for node in nodes:
			resources = cost_table.nodeRes_table[node]
			#bstr = bstr + generateMappingConstraints(node,resources)
			#bstr = bstr + generateLatencyConstraints(node,resources)
	return bstr

def generateMappingConstraints(node,resources):
	bstr=''
	names=[]
	for res in resources:
		names.append(mappingName(node,res))
	bstr=bstr+"+".join(names)+"=1\n"
	return bstr

def generateLatencyConstraints(node,resources):
	bstr = ''
	bstr = bstr + generateNodeLatency(node)
	for res in resources:
		bstr = bstr + " - {rlatency} ".format(rlatency=res.latency) + mappingName(node,res)
	bstr = bstr + ' = 0\n'
	return bstr

# Generates resource concurrency constrains for each resource
def generateResourceConcurrencyConstraints(dfg,cost_table):
	bstr=""
	bstr=bstr+"\n\\ Resource Concurrency\n"
	for (res,nodes) in cost_table.res_nodes.items():
		bstr = bstr + generateResourceConcurrencyConstraint(res,nodes)
	return bstr

def generateResourceConcurrencyConstraint(res,nodes):
	bstr = '\n\\ \t Resource Concurrency Constraint for Resource {rid}\n'.format(rid=res.name)
	for step in range(1,max_latency):
	#for step in range(res.latency+1,max_latency):
		step_vars = []
		for node in nodes:
			#if node.asap > step:
			#	continue
			#if node.alap < (step-res.latency):
			#	continue
			start_step = max(node.asap,step-res.latency)
			end_step= min(node.alap,step)
			#for i in range(start_step,end_step):
			for cycle in range(num_cycles):
				step_vars.append(generateNodeControlStep(node,step,cycle))
		bstr = bstr + " + ".join(step_vars) + " <= {num}\n".format(num=res.number)
	bstr += "\n"
	return bstr

def generateProcessorConstraints(dfg, cost_table):
	for (res,nodes) in cost_table.res_nodes.items():
		for node in nodes:
			print node.name
	bstr = ""
	bstr = bstr + "\n\\ Processor constraints\n"
	for step in range(1,max_latency):
		step_vars = []
		for node in cost_table.nodes:
			for cycle in range(num_cycles):
				step_vars.append(node.name + "_" + str(step) + "_" + str(cycle))
		bstr = bstr + " + ".join(step_vars) + " <= {num}\n".format(num=num_processors)
	return bstr

# Sets bounds on variables
def generateVarBounds():
	global binary_variables,timing_variables
	bstr="\n\\Bounds on Decisions Variables\n"
	bstr=bstr+"Bounds\n"
	for var in binary_variables:
		bstr=bstr+"0 <= %20s <= 1\n" % (var)

	for var in timing_variables:
		bstr=bstr+"0 <= %20s <= %d\n" % (var,100)
	return bstr

# Lists names of all binary variables
def generateVarTypes():
	global binary_variables
	bstr="General\n"
	for var in binary_variables:
		bstr=bstr+'\t'+var + '\n'
	return bstr

# Creates variable names such as 'n1_START' (n1 being the node name), n1_START equals the time at which n1 starts executing 
def generateNodeStartTime(node,cycle):
	global timing_variables
	newname =node.name+"_START_" + str(cycle)
	timing_variables.append(newname)
	return newname

# Creates variable names such as 'ALU_n1', ALU_n1 = 1 => n1 is bound to ALU 
def mappingName(node,res):
	global binary_variables
	newname =res.name+"_"+node.name
	binary_variables.append(newname)
	return newname

# Creates variable names such as 'n1_latency'
def generateNodeLatency(node):
	global timing_variables
	name=node.name+"_latency"
	timing_variables.append(name)
	return name

# Creates variable names such as 'n1_1', n1_3 = 1 => n1 starts executing at timeunit = 3 
def generateNodeControlStep(node,step,cycle):
	global binary_variables
	name=node.name+ "_"+str(step) + "_" + str(cycle)
	binary_variables.append(name)
	return name

def sortDictByKeys(dictionary):
	"""
	input: dictionary is a dictionary
	output: sorted_dict, a tuple sorted by keys of the dictionary
	"""
	sorted_dict = sorted(dictionary.iteritems(),key=operator.itemgetter(0))
	return sorted_dict
